"""initial_schema_workflows_runs_logs_nodes

Revision ID: 72a4879a3d05
Revises: 
Create Date: 2026-02-01 00:03:29.685835

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import sqlite

# revision identifiers, used by Alembic.
revision: str = '72a4879a3d05'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('workflows',
    sa.Column('id', sa.String(length=64), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('status', sa.String(length=32), nullable=False, comment='draft | published | archived'),
    sa.Column('version', sa.String(length=32), nullable=False),
    sa.Column('graph_definition', sqlite.JSON(), nullable=True, comment='WorkflowDefinition JSON: {nodes, edges, entry_point}'),
    sa.Column('parameters', sqlite.JSON(), nullable=True, comment='Default workflow parameters'),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('workflows', schema=None) as batch_op:
        batch_op.create_index('ix_workflows_status', ['status'], unique=False)
        batch_op.create_index('ix_workflows_updated_at', ['updated_at'], unique=False)

    op.create_table('workflow_runs',
    sa.Column('id', sa.String(length=64), nullable=False),
    sa.Column('workflow_id', sa.String(length=64), nullable=False),
    sa.Column('status', sa.String(length=32), nullable=False, comment='pending | running | completed | failed | cancelled'),
    sa.Column('triggered_by', sa.String(length=128), nullable=True),
    sa.Column('temporal_workflow_id', sa.String(length=255), nullable=True, comment='Temporal workflow execution ID'),
    sa.Column('temporal_run_id', sa.String(length=255), nullable=True, comment='Temporal run ID'),
    sa.Column('input_data', sqlite.JSON(), nullable=True, comment='Run input parameters'),
    sa.Column('output_data', sqlite.JSON(), nullable=True, comment='Final run output'),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('ended_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['workflow_id'], ['workflows.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('workflow_runs', schema=None) as batch_op:
        batch_op.create_index('ix_runs_started_at', ['started_at'], unique=False)
        batch_op.create_index('ix_runs_status', ['status'], unique=False)
        batch_op.create_index('ix_runs_workflow_id', ['workflow_id'], unique=False)

    op.create_table('execution_logs',
    sa.Column('id', sa.String(length=64), nullable=False),
    sa.Column('run_id', sa.String(length=64), nullable=False),
    sa.Column('node_id', sa.String(length=128), nullable=True, comment='Associated node ID (null for workflow-level logs)'),
    sa.Column('level', sa.String(length=16), nullable=False, comment='debug | info | warning | error'),
    sa.Column('message', sa.Text(), nullable=False),
    sa.Column('source', sa.String(length=64), nullable=False, comment='system | worker | api | node'),
    sa.Column('extra_data', sqlite.JSON(), nullable=True, comment='Additional structured log data'),
    sa.Column('timestamp', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['run_id'], ['workflow_runs.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('execution_logs', schema=None) as batch_op:
        batch_op.create_index('ix_logs_level', ['level'], unique=False)
        batch_op.create_index('ix_logs_node_id', ['node_id'], unique=False)
        batch_op.create_index('ix_logs_run_id', ['run_id'], unique=False)
        batch_op.create_index('ix_logs_timestamp', ['timestamp'], unique=False)

    op.create_table('node_executions',
    sa.Column('id', sa.String(length=64), nullable=False),
    sa.Column('run_id', sa.String(length=64), nullable=False),
    sa.Column('node_id', sa.String(length=128), nullable=False, comment='Node ID within the workflow graph'),
    sa.Column('node_type', sa.String(length=64), nullable=False, comment='Node type from registry'),
    sa.Column('status', sa.String(length=32), nullable=False, comment='pending | running | completed | failed | skipped'),
    sa.Column('execution_order', sa.Integer(), nullable=False),
    sa.Column('input_data', sqlite.JSON(), nullable=True),
    sa.Column('output_data', sqlite.JSON(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('ended_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('duration_ms', sa.Float(), nullable=True, comment='Execution duration in milliseconds'),
    sa.ForeignKeyConstraint(['run_id'], ['workflow_runs.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('node_executions', schema=None) as batch_op:
        batch_op.create_index('ix_node_exec_node_id', ['node_id'], unique=False)
        batch_op.create_index('ix_node_exec_run_id', ['run_id'], unique=False)
        batch_op.create_index('ix_node_exec_status', ['status'], unique=False)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('node_executions', schema=None) as batch_op:
        batch_op.drop_index('ix_node_exec_status')
        batch_op.drop_index('ix_node_exec_run_id')
        batch_op.drop_index('ix_node_exec_node_id')

    op.drop_table('node_executions')
    with op.batch_alter_table('execution_logs', schema=None) as batch_op:
        batch_op.drop_index('ix_logs_timestamp')
        batch_op.drop_index('ix_logs_run_id')
        batch_op.drop_index('ix_logs_node_id')
        batch_op.drop_index('ix_logs_level')

    op.drop_table('execution_logs')
    with op.batch_alter_table('workflow_runs', schema=None) as batch_op:
        batch_op.drop_index('ix_runs_workflow_id')
        batch_op.drop_index('ix_runs_status')
        batch_op.drop_index('ix_runs_started_at')

    op.drop_table('workflow_runs')
    with op.batch_alter_table('workflows', schema=None) as batch_op:
        batch_op.drop_index('ix_workflows_updated_at')
        batch_op.drop_index('ix_workflows_status')

    op.drop_table('workflows')
    # ### end Alembic commands ###
